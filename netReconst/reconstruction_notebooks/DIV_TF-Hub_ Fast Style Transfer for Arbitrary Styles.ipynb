{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DIV&TF-Hub: Fast Style Transfer for Arbitrary Styles.ipynb","private_outputs":true,"provenance":[{"file_id":"https://github.com/tensorflow/hub/blob/master/examples/colab/tf2_arbitrary_image_stylization.ipynb","timestamp":1613739035971}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HbZYDBnOfUqx"},"source":["# Research note:\n","\n","We develope upon this work two approach:\n","\n","* FTS online from two pictures from Imgur.\n","\n","* DIV&FTS online from two pictures from Google Drive. (under development)"]},{"cell_type":"markdown","metadata":{"id":"ScitaPqhKtuW"},"source":["##### Copyright 2019 The TensorFlow Hub Authors.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");"]},{"cell_type":"code","metadata":{"id":"jvztxQ6VsK2k"},"source":["# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# =============================================================================="],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oXlcl8lqBgAD"},"source":["# Fast Style Transfer for Arbitrary Styles\n"]},{"cell_type":"markdown","metadata":{"id":"MfBg1C5NB3X0"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_arbitrary_image_stylization.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/tf2_arbitrary_image_stylization.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/tf2_arbitrary_image_stylization.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","  <td>\n","    <a href=\"https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"YeeuYzbZcJzs"},"source":["Based on the model code in [magenta](https://github.com/tensorflow/magenta/tree/master/magenta/models/arbitrary_image_stylization) and the publication:\n","\n","[Exploring the structure of a real-time, arbitrary neural artistic stylization\n","network](https://arxiv.org/abs/1705.06830).\n","*Golnaz Ghiasi, Honglak Lee,\n","Manjunath Kudlur, Vincent Dumoulin, Jonathon Shlens*,\n","Proceedings of the British Machine Vision Conference (BMVC), 2017.\n"]},{"cell_type":"markdown","metadata":{"id":"TaM8BVxrCA2E"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"J65jog2ncJzt"},"source":["Let's start with importing TF-2 and all relevant dependencies."]},{"cell_type":"code","metadata":{"id":"v-KXRY5XBu2u"},"source":["import functools\n","import os\n","\n","from matplotlib import gridspec\n","import matplotlib.pylab as plt\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","print(\"TF Version: \", tf.__version__)\n","print(\"TF-Hub version: \", hub.__version__)\n","print(\"Eager mode enabled: \", tf.executing_eagerly())\n","print(\"GPU available: \", tf.test.is_gpu_available())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tsoDv_9geoZn"},"source":["# @title Define image loading and visualization functions  { display-mode: \"form\" }\n","\n","def crop_center(image):\n","  \"\"\"Returns a cropped square image.\"\"\"\n","  shape = image.shape\n","  new_shape = min(shape[1], shape[2])\n","  offset_y = max(shape[1] - shape[2], 0) // 2\n","  offset_x = max(shape[2] - shape[1], 0) // 2\n","  image = tf.image.crop_to_bounding_box(\n","      image, offset_y, offset_x, new_shape, new_shape)\n","  return image\n","\n","@functools.lru_cache(maxsize=None)\n","def load_image(image_url, image_size=(256, 256), preserve_aspect_ratio=True):\n","  \"\"\"Loads and preprocesses images.\"\"\"\n","  # Cache image file locally.\n","  image_path = tf.keras.utils.get_file(os.path.basename(image_url)[-128:], image_url)\n","  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n","  img = plt.imread(image_path).astype(np.float32)[np.newaxis, ...]\n","  if img.max() > 1.0:\n","    img = img / 255.\n","  if len(img.shape) == 3:\n","    img = tf.stack([img, img, img], axis=-1)\n","  img = crop_center(img)\n","  img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n","  return img\n","\n","def show_n(images, titles=('',)):\n","  n = len(images)\n","  image_sizes = [image.shape[1] for image in images]\n","  w = (image_sizes[0] * 6) // 320\n","  plt.figure(figsize=(w  * n, w))\n","  gs = gridspec.GridSpec(1, n, width_ratios=image_sizes)\n","  for i in range(n):\n","    plt.subplot(gs[i])\n","    plt.imshow(images[i][0], aspect='equal')\n","    plt.axis('off')\n","    plt.title(titles[i] if len(titles) > i else '')\n","  plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8etHh05-CJHc"},"source":["Let's get as well some images to play with.\n","The pictures in this first part It's from Imgur."]},{"cell_type":"code","metadata":{"id":"dRc0vat3Alzo"},"source":["# @title Load example images  { display-mode: \"form\" }\n","\n","damage_image_url = 'https://i.imgur.com/V1fXu1E.jpg'  # @param {type:\"string\"}\n","style_image_url = 'https://i.imgur.com/hAWzSJX.jpg'  # @param {type:\"string\"}\n","output_image_size = 384  # @param {type:\"integer\"}\n","\n","# The content image size can be arbitrary.\n","content_img_size = (output_image_size, output_image_size)\n","# The style prediction model was trained with image size 256 and it's the \n","# recommended image size for the style image (though, other sizes work as \n","# well but will lead to different results).\n","style_img_size = (256, 256)  # Recommended to keep it at 256.\n","\n","content_image = load_image(damage_image_url, content_img_size)\n","style_image = load_image(style_image_url, style_img_size)\n","style_image = tf.nn.avg_pool(style_image, ksize=[3,3], strides=[1,1], padding='SAME')\n","show_n([content_image, style_image], ['Content image', 'Style image'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yL2Bn5ThR1nY"},"source":["## Import TF-Hub module"]},{"cell_type":"code","metadata":{"id":"467AVDSuzBPc"},"source":["# Load TF-Hub module.\n","\n","hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n","hub_module = hub.load(hub_handle)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uAR70_3wLEDB"},"source":["The signature of this hub module for image stylization is:\n","```\n","outputs = hub_module(content_image, style_image)\n","stylized_image = outputs[0]\n","```\n","Where `content_image`, `style_image`, and `stylized_image` are expected to be 4-D Tensors with shapes `[batch_size, image_height, image_width, 3]`.\n","\n","In the current example we provide only single images and therefore the batch dimension is 1, but one can use the same module to process more images at the same time.\n","\n","The input and output values of the images should be in the range [0, 1].\n","\n","The shapes of content and style image don't have to match. Output image shape\n","is the same as the content image shape."]},{"cell_type":"markdown","metadata":{"id":"qEhYJno1R7rP"},"source":["## Demonstrate image stylization"]},{"cell_type":"code","metadata":{"id":"lnAv-F3O9fLV"},"source":["# Stylize content image with given style image.\n","# This is pretty fast within a few milliseconds on a GPU.\n","\n","outputs = hub_module(tf.constant(content_image), tf.constant(style_image))\n","stylized_image = outputs[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OEAPEdq698gs"},"source":["# Visualize input images and the generated stylized image.\n","\n","show_n([content_image, style_image, stylized_image], titles=['Damage', 'Style image', 'Repared'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wh4j78ZvglxR"},"source":["# DIV&FTS\n","\n","## Div and conquer algorithm plus OpenCV.\n","\n","Implementation of divide big pictures\n","\n","https://towardsdatascience.com/images-and-masks-splitting-into-multiple-pieces-in-python-with-google-colab-2f6b2ddcb322\n","\n","You need download two pictures from Imgur and upload to folder structure of this project:\n","\n","\n","*   https://i.imgur.com/V1fXu1E.jpg\n","*   https://i.imgur.com/hAWzSJX.jpg\n","\n","Remember delete the pictures in Imput dir, and replace with other examples.\n","\n","Folder structure:\n","\n","*   Folder DIV&FTS\\\n","   + Imput dir\\\n","      - original\\ V1fXu1E.jpg\n","\n","      - damaged\\ hAWzSJX.jpg\n","   + Output dir\\\n","      - originals\\ slice pictures result\n","\n","      - damages\\ slice pictures result"]},{"cell_type":"code","metadata":{"id":"C6PEg_fXj51R"},"source":["import os\n","import sys\n","import shutil\n","import glob\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from PIL import Image\n","# for impaint\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m6x8WJC-j6y_"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"If0R9gZhj9jY"},"source":["%cd gdrive/My Drive/Folder DIV&FTS"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iMlI165DkBLy"},"source":["def dir_create(path):\n","    \"\"\"Dir create function.\n","        \n","        Create and clean a directory recrusive,\n"," \n","    \"\"\"\n","    if (os.path.exists(path)) and (os.listdir(path) != []):\n","        shutil.rmtree(path)\n","        os.makedirs(path)\n","    if not os.path.exists(path):\n","        os.makedirs(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XgRfKrZ3kLkK"},"source":["def crop(input_file, height, width):\n","    img = Image.open(input_file)\n","    img_width, img_height = img.size\n","    for i in range(img_height//height):\n","        for j in range(img_width//width):\n","            box = (j*width, i*height, (j+1)*width, (i+1)*height)\n","            yield img.crop(box)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2At_43hskSrl"},"source":["def split(inp_img_dir, inp_msk_dir, out_dir, height, width, \n","          start_num):\n","    image_dir = os.path.join(out_dir, 'originals')\n","    mask_dir = os.path.join(out_dir, 'damages')\n","    dir_create(out_dir)\n","    dir_create(image_dir)\n","    dir_create(mask_dir)\n","    img_list = [f for f in\n","                os.listdir(inp_img_dir)\n","                if os.path.isfile(os.path.join(inp_img_dir, f))]\n","    file_num = 0\n","    for infile in img_list:\n","        print(infile)\n","        infile_path = os.path.join(inp_img_dir, infile)\n","        for k, piece in enumerate(crop(infile_path,\n","                                       height, width), start_num):\n","            img = Image.new('RGB', (height, width), 255)\n","            img.paste(piece)\n","            img_path = os.path.join(image_dir, \n","                                    infile.split('.')[0]+ '_'\n","                                    + str(k).zfill(5) + '.jpg')\n","            img.save(img_path)\n","\n","    img_list = [f for f in\n","                os.listdir(inp_msk_dir)\n","                if os.path.isfile(os.path.join(inp_msk_dir, f))]\n","    file_num = 0\n","    for infile in img_list:\n","        print(infile)\n","        infile_path = os.path.join(inp_msk_dir,\n","                                   infile.split('.')[0] + '.jpg')\n","        for k, piece in enumerate(crop(infile_path,\n","                                       height, width), start_num):\n","            msk = Image.new('RGB', (height, width), 255)\n","            msk.paste(piece)\n","            msk_path = os.path.join(mask_dir,\n","                                    infile.split('.')[0] + '_'\n","                                    + str(k).zfill(5) + '.jpg')\n","            msk.save(msk_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GhvEFcn8kTsw"},"source":["inp_img_dir = \"./input_dir/original\"\n","inp_msk_dir = \"./input_dir/damaged\"\n","out_dir = \"./output_dir\"\n","height = 512\n","width = 512\n","start_num = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aKL09s8QkXNJ"},"source":["input_images_list = glob.glob(inp_img_dir + \"/*.jpg\")\n","input_masks_list = glob.glob(inp_msk_dir + \"/*.jpg\")\n","\n","split(inp_img_dir, inp_msk_dir, out_dir, height, width, start_num)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5HVnZ7f0kakv"},"source":["for i, (image_path, mask_path) in enumerate(zip(input_images_list,\n","                                                input_masks_list)):\n","    fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(18, 9))\n","    image = mpimg.imread(image_path)\n","    mask = mpimg.imread(mask_path)\n","    ax1.set_title(\"Original \" + str(i+1))\n","    ax1.imshow(image)\n","    ax2.imshow(mask)\n","    ax2.set_title(\"Damaged \" + str(i+1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IbQ2v4ZCkhYu"},"source":["def image_part_plotter(images_list, offset,rows='', cols=''):\n","    \"\"\"Image part plotter function.\n","\n","        This function received the variables:\n","        + A list of images\n","        + Offset number (don't touch!)\n","        + number of rows\n","        + number of columns (self regulated for the length of the image list)\n","        \n","    \"\"\"\n","    fig = plt.figure(figsize=(12, 6))\n","    columns = cols\n","    rows = rows\n","    # ax enables access to manipulate each of subplots\n","    ax = []\n","    for i in range(columns*rows):\n","        # create subplot and append to ax\n","        img = mpimg.imread(images_list[i+offset])\n","        ax.append(fig.add_subplot(rows, columns, i+1))\n","        ax[-1].set_title(\"Nº\" + str(i+1))\n","        plt.imshow(img)\n","        plt.axis(\"off\")\n","    plt.show() # Render the plot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d97p7NcJkk_J"},"source":["# This cell work together with cell 47\n","out_img_dir = \"./output_dir/originals\"\n","out_msk_dir = \"./output_dir/damages\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k2GTEiuMkn61"},"source":["# We need this cell with the list of pictures and masks and iterate over the list\n","# and pass each pic in impairment code\n","output_originals_list = glob.glob(out_img_dir + \"/*.jpg\")\n","output_damages_list = glob.glob(out_msk_dir + \"/*.jpg\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fs3zeVOOksXA"},"source":["image_part_plotter(output_originals_list,0,rows=1, cols=len(output_originals_list))\n","image_part_plotter(output_damages_list, 0,rows=1, cols=len(output_damages_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jaCBtgNHk0M0"},"source":["def style_transfer_part_plotter(originals_list, damages_list, offset,rows='', cols=''):\n","    \"\"\"Impaint part plotter function.\n","\n","        This function received the variables:\n","        + A list of images\n","        + A list of masks\n","        + Offset number (don't touch!)\n","        + number of rows\n","        + number of columns (self regulated for the length of the image list)\n","\n","        Then return a set of plotted and repaired by impainting pic slices.\n","        \n","    \"\"\"\n","    fig = plt.figure(figsize=(12, 6))\n","    columns = cols\n","    rows = rows\n","    # ax enables access to manipulate each of subplots\n","    ax = []\n","    for i in range(columns*rows):\n","        \n","        # Stylize content image with given style image.\n","        # This is pretty fast within a few milliseconds on a GPU.\n","\n","        outputs = hub_module(tf.constant(damages_list[i+offset]), tf.constant(originals_list[i+offset]))\n","        stylized_image = outputs[0]\n","\n","        # create subplot and append to ax\n","        ax.append(fig.add_subplot(rows, columns, i+1))\n","        ax[-1].set_title(\"Nº\" + str(i+1))\n","        plt.imshow(stylized_image)\n","        plt.axis(\"off\")\n","    plt.show() # Render the plot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nyTuPb1Wk3l9"},"source":["style_transfer_part_plotter(output_images_list,output_masks_list,0,rows=1, cols=len(output_images_list))"],"execution_count":null,"outputs":[]}]}